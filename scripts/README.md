# Scripts

This directory contains utility scripts for the Lakeflow Community Connectors project.

## merge_python_source.py

Merges multiple source files into a single deployable Python file. This is useful for creating standalone source connectors that can be deployed without the full project structure.

By default, the merged file is saved as `_generated_{source_name}_python_source.py` in the same directory as the source implementation.

### What it does

The script combines three essential components into one file:

1. **libs/utils.py** - Parsing utilities for converting JSON data to PySpark types
2. **sources/{source_name}/{source_name}.py** - The source connector implementation (LakeflowConnect class)
3. **pipeline/lakeflow_python_source.py** - PySpark DataSource registration code

### Usage

```bash
# Basic usage - saves to sources/{source_name}/_generated_{source_name}_python_source.py
python3 scripts/merge_python_source.py <source_name>

# Save to a custom file location
python3 scripts/merge_python_source.py <source_name> -o <output_file>
```

### Examples

```bash
# Merge Zendesk source (saves to sources/zendesk/_generated_zendesk_python_source.py)
python3 scripts/merge_python_source.py zendesk

# Merge Example source (saves to sources/example/_generated_example_python_source.py)
python3 scripts/merge_python_source.py example

# Merge Zendesk source and save to custom location
python3 scripts/merge_python_source.py zendesk -o output/zendesk_merged.py
```

### Requirements

- Python 3.6 or higher (use `python3` command if your system has both Python 2 and 3)
- The source must exist in `sources/{source_name}/{source_name}.py`

### Output Format

The merged file has the following structure:
- All imports are extracted and placed at the top (deduplicated)
- All code is wrapped in a `register_lakeflow_source(spark)` function
- Three sections with clear headers showing the source files

```python
# ==============================================================================
# Merged Lakeflow Source: {source_name}
# ==============================================================================
# This file is auto-generated by scripts/merge_python_source.py
# ==============================================================================

# All imports at the top
from typing import Iterator
from pyspark.sql import Row
from pyspark.sql.datasource import DataSource
# ... other imports ...


def register_lakeflow_source(spark):
    """Register the Lakeflow Python source with Spark."""

    ########################################################
    # libs/utils.py
    ########################################################

    def parse_value(value, field_type):
        # ... content from libs/utils.py ...
    
    ########################################################
    # sources/{source_name}/{source_name}.py
    ########################################################

    class LakeflowConnect:
        # ... content from sources/{source_name}/{source_name}.py ...

    ########################################################
    # pipeline/lakeflow_python_source.py
    ########################################################

    class LakeflowSource(DataSource):
        # ... content from pipeline/lakeflow_python_source.py ...
    
    # Register the data source with Spark
    spark.dataSource.register(LakeflowSource)
```

### Help

```bash
python3 scripts/merge_python_source.py --help
```

